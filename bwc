#!/usr/bin/env bash
version="v0.1";

bwchelp(){
    echo "\
BWC $version -GPL v3
Usage: bwc [-h] [-o] [-c]\
";
}

bwcoptions(){
echo "\
-h > show help/info
-o > show options
-c > crawl starting with a specific website";
}

dirsetup(){
read -p "Type the name of the site you would like to start on, please disclude http:// or https:// (i.e. www.spencerbravo.com):
\
" startsite
if [[ ! -d "$HOME/crawl/" ]]; then
    mkdir "$HOME/crawl/";
fi
if [[ ! -d "$HOME/crawl/$startsite" ]]; then
    mkdir "$HOME/crawl/$startsite";
dir="$HOME/crawl/$startsite";
else
    declare -i count=1;
    arg="f";
    while [[ $arg == "f" ]]; do
        if [[ ! -d "$HOME/crawl/$startsite($count)" ]]; then
            mkdir "$HOME/crawl/$startsite($count)";
            arg="t";
        else
            count=$count+1;
            arg="f";
        fi
        dir="$HOME/crawl/$startsite($count)";
    done
fi
}
crawler(){
    dirsetup;
    wget $startsite --quiet --output-document=$dir/index;
        
#figure out how to take just url out of file (v dev v)
#echo '<a href="codeshrub.com">'  | sed 's/\("\).*/\1/g'


}




if [[ $1 == "" ]]; then
    bwchelp;
elif [[ $1 == -h ]]; then
    bwchelp;
elif [[ $1 == -o ]]; then
    bwcoptions;
elif [[ $1 == -c ]]; then
    crawler;
fi
