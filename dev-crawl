#!/bin/bash
VISITED_URLS_FILE="$HOME/crawler_visited_urls"
     
EXPR_URL_MATCH="http://[^'\"]\+\.html"
     
EXPRESSION="[A-Za-z0-9._%\\+-]\\+@[A-Za-z0-9.-]\\+\\.[A-Za-z]\\{2,6\\}"
     
RUNTIME=30
     
WGET_TIMEOUT=10
WGET_RETRIES=0
     
START_TIME=`date +%s`
     
if [[ "$CRAWLER_RECURSION" == "" ]]; then
    rm -f $VISITED_URLS_FILE
    export CRAWLER_RECURSION=1
     
    touch $VISITED_URLS_FILE
else
    let CRAWLER_RECURSION++
fi
     
     
while getopts e:t:s OPTION; do
case "$OPTION" in
    *)
        echo "nothing"
        SUMMARY=1
    ;;
    esac
    done
 
    if [[ $RUNTIME -le 0 ]]; then
            exit 0
    fi
     
    while shift; do
            if [[ "$1" == *://* ]]; then
                    URL=$1
                    break
            fi
    done
     
    if [[ "$DEBUG" != "" ]]; then
            echo ">> $URL / T=$RUNTIME / CRAWLER_RECURSION=$CRAWLER_RECURSION"
    fi
     
    if [ "$URL" == "" ]; then
            echo "Syntax: $0 [-e expression] [-t runtime] [-s] URL"
            exit 1
    fi
     
    TMP_PAGE=`mktemp`
    wget $URL -t $WGET_RETRIES -T $WGET_TIMEOUT -qO $TMP_PAGE
    echo $URL >> $VISITED_URLS_FILE
     
    if [ $? != 0 ]; then
            rm $TMP_PAGE
            exit $?
    fi
     
    RESULTS=`grep -no $EXPRESSION $TMP_PAGE`
     
    for result in $RESULTS; do
            echo "$URL $result"
     
            read LINE DATA <<< `echo $result |tr ":" " "`
    done
     
    URL_LIST=`grep -o $EXPR_URL_MATCH $TMP_PAGE`
     
    rm $TMP_PAGE
     
    for u in $URL_LIST; do
            CURRENT_TIME=`date +%s`
     
            if [[ $(($START_TIME + $RUNTIME)) -le $CURRENT_TIME ]]; then
                    break
            fi
     
            if [[ ! `grep -o $u $VISITED_URLS_FILE` ]]; then
                    $0 -t $(($RUNTIME - ($CURRENT_TIME - $START_TIME))) -e $EXPRESSION $u
            fi
    done
     
     
    if [[ "$SUMMARY" != "" ]]; then
            URLS_VISITED=`wc -l $VISITED_URLS_FILE |cut -d " " -f 1`
            ELAPSED_TIME=$((`date +%s` - $START_TIME))
    fi
     
     
    if [[ "$CRAWLER_RECURSION" == "1" ]]; then
            #rm $VISITED_URLS_FILE
            unset CRAWLER_RECURSION
    fi
     
    let CRAWLER_RECURSION--

